{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdf078f2",
   "metadata": {},
   "source": [
    "# JAX / XLA Whole-Program Training Optimizer\n",
    "This notebook demonstrates how to use `jax.jit` to compile an entire training step into a single XLA-optimized kernel, significantly reducing execution latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b57ba1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "from core.model import init_params\n",
    "from core.trainer import step\n",
    "\n",
    "# Initialize data and parameters exactly as in the project\n",
    "key = jax.random.PRNGKey(0)\n",
    "x = jax.random.normal(key, (128, 128))\n",
    "y = jax.random.normal(key, (128, 10))\n",
    "params = init_params(128, 10, key)\n",
    "\n",
    "print(f\"Devices detected: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e886d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Warmup: The first call triggers the XLA compiler\n",
    "print(\"Compiling training step...\")\n",
    "_ = step(params, x, y)\n",
    "\n",
    "# Performance Benchmark\n",
    "print(\"Running benchmark for 50 steps...\")\n",
    "t0 = time.time()\n",
    "for _ in range(50):\n",
    "    loss, grads = step(params, x, y)\n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"Optimization Complete.\")\n",
    "print(f\"Average JIT time per step: {(t1-t0)/50*1000:.4f} ms\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
